<!-- Generated by SpecStory -->

# Continue with the to-do list (2025-06-13 16:52:55)

_**User**_

@todo.md continue

---

_**Assistant**_



---

I'll help you continue with the todo.md file. Let me first examine the current state of the project to see what containers exist and what benchmarks/tests are currently available.

---

<details>
            <summary>Listed current directory • **33** results</summary>
        
| Name |
|-------|
| 📁 `.git` |
| 📁 `.vscode` |
| 📁 `Containers` |
| 📄 `CHANGELOG.md` |
| 📄 `VERSION.md` |
| 📁 `Containers.Benchmarks` |
| 📁 `Containers.Test` |
| 📄 `README.md` |
| 📁 `BenchmarkDotNet.Artifacts` |
| 📁 `scripts` |
| 📄 `Containers.sln` |
| 📄 `COPYRIGHT.md` |
| 📁 `.specstory` |
| 📄 `.cursorignore` |
| 📁 `.cursor` |
| 📄 `.cursorindexingignore` |
| 📄 `Directory.Packages.props` |
| 📄 `AUTHORS.md` |
| 📄 `.gitignore` |
| 📄 `.runsettings` |
| 📄 `.editorconfig` |
| 📄 `global.json` |
| 📁 `TestResults` |
| 📄 `PROJECT_URL.url` |
| 📄 `LICENSE.md` |
| 📄 `.mailmap` |
| 📄 `.gitattributes` |
| 📄 `TAGS.md` |
| 📄 `DESCRIPTION.md` |
| 📁 `.vs` |
| 📁 `.github` |
| 📄 `AUTHORS.url` |
| 📄 `icon.png` |

</details>

---

Now let me examine the containers, benchmarks, and test directories to see what's currently implemented:

---

<details>
            <summary>Listed directory Containers • **14** results</summary>
        
| Name |
|-------|
| 📄 `todo.md` |
| 📄 `ContiguousMap.cs` |
| 📁 `obj` |
| 📄 `ContiguousSet.cs` |
| 📄 `ContiguousCollection.cs` |
| 📄 `InsertionOrderMap.cs` |
| 📄 `InsertionOrderSet.cs` |
| 📄 `InsertionOrderCollection.cs` |
| 📄 `OrderedMap.cs` |
| 📁 `bin` |
| 📄 `OrderedSet.cs` |
| 📄 `RingBuffer.cs` |
| 📄 `OrderedCollection.cs` |
| 📄 `Containers.csproj` |

</details>

---

<details>
            <summary>Listed directory Containers.Benchmarks • **15** results</summary>
        
| Name |
|-------|
| 📁 `obj` |
| 📁 `bin` |
| 📄 `OrderedMapBenchmarks.cs` |
| 📄 `GlobalSuppressions.cs` |
| 📄 `BENCHMARKING_SUMMARY.md` |
| 📄 `PerformanceAnalysisBenchmarks.cs` |
| 📄 `CrossCollectionComparisonBenchmarks.cs` |
| 📄 `StandardCollectionBenchmarks.cs` |
| 📄 `BENCHMARKING_PROCESS.md` |
| 📄 `Containers.Benchmarks.csproj` |
| 📄 `RingBufferBenchmarks.cs` |
| 📄 `OrderedSetBenchmarks.cs` |
| 📄 `OrderedCollectionBenchmarks.cs` |
| 📄 `Program.cs` |
| 📄 `README.md` |

</details>

---

<details>
            <summary>Listed directory Containers.Test • **7** results</summary>
        
| Name |
|-------|
| 📁 `obj` |
| 📄 `OrderedMapTests.cs` |
| 📄 `OrderedSetTests.cs` |
| 📄 `RingBufferTests.cs` |
| 📄 `OrderedCollectionTests.cs` |
| 📄 `Containers.Test.csproj` |
| 📁 `bin` |

</details>

---

Now I can see what's missing. Let me analyze the situation:

**Current Containers:**
- OrderedCollection ✅
- OrderedSet ✅
- OrderedMap ✅
- RingBuffer ✅
- InsertionOrderCollection
- InsertionOrderSet
- InsertionOrderMap
- ContiguousCollection
- ContiguousSet
- ContiguousMap

**Current Benchmarks:**
- OrderedCollectionBenchmarks ✅
- OrderedSetBenchmarks ✅
- OrderedMapBenchmarks ✅
- RingBufferBenchmarks ✅
- Missing: InsertionOrder and Contiguous collections benchmarks

**Current Tests:**
- OrderedCollectionTests ✅
- OrderedSetTests ✅
- OrderedMapTests ✅
- RingBufferTests ✅
- Missing: InsertionOrder and Contiguous collections tests

Let me update the todo.md file to be more specific about what's needed:

---

```diff
  ✅ generic set guaranteed to allocate in contiguous memory (DONE) 
  ✅ generic map guaranteed to allocate in contiguous memory (DONE)
+ 
+ **Missing Benchmarks:**
+ - [ ] InsertionOrderCollectionBenchmarks.cs
+ - [ ] InsertionOrderSetBenchmarks.cs
+ - [ ] InsertionOrderMapBenchmarks.cs
+ - [ ] ContiguousCollectionBenchmarks.cs
+ - [ ] ContiguousSetBenchmarks.cs
+ - [ ] ContiguousMapBenchmarks.cs
+ 
+ **Missing Tests:**
+ - [ ] InsertionOrderCollectionTests.cs
+ - [ ] InsertionOrderSetTests.cs
+ - [ ] InsertionOrderMapTests.cs
+ - [ ] ContiguousCollectionTests.cs
+ - [ ] ContiguousSetTests.cs
+ - [ ] ContiguousMapTests.cs
  
  add all containers to the benchmarks and tests as they are implemented
```

---

Now let me remove the old generic line at the bottom since we've made it more specific:

---



---

Perfect! I've updated the `todo.md` file to provide a clear roadmap of what's still needed. The file now shows:

1. ✅ **All main containers are implemented** - All the core collection types are done
2. 📋 **Clear breakdown of missing work** - 6 benchmark files and 6 test files still need to be created

This gives you a concrete action plan for completing the project. Each of the newly implemented containers (InsertionOrder* and Contiguous*) needs corresponding benchmark and test files to match the existing pattern established by the OrderedCollection, OrderedSet, OrderedMap, and RingBuffer implementations.

Would you like me to help implement any of these missing benchmarks or tests?

---

_**User**_

yes implement the remaining work

---

_**Assistant**_



---

I'll implement all the remaining benchmarks and tests. Let me first examine the existing patterns to ensure consistency, then create all the missing files.

---

Read file: Containers.Benchmarks/OrderedCollectionBenchmarks.cs

---

Read file: Containers.Test/OrderedCollectionTests.cs

---

Now let me examine one of the insertion order collections to understand their API:

---

Read file: Containers/InsertionOrderCollection.cs

---

Now let me examine one of the contiguous collections:

---

Read file: Containers/ContiguousCollection.cs

---

Now I'll start implementing the missing benchmarks and tests. Let me start with the benchmark files:

---



---

Now let me create the rest of the benchmark files in parallel:

---

```diff
- 
+ // Copyright (c) ktsu.dev
+ // All rights reserved.
+ // Licensed under the MIT license.
+ 
+ using BenchmarkDotNet.Attributes;
+ using ktsu.Containers;
+ 
+ namespace ktsu.Containers.Benchmarks;
+ 
+ /// <summary>
+ /// Benchmarks for InsertionOrderSet performance compared to built-in collections.
+ /// </summary>
+ [MemoryDiagnoser]
+ [SimpleJob]
+ public class InsertionOrderSetBenchmarks
+ {
+ 	private readonly Random random = new(42); // Fixed seed for reproducible results
+ 	private int[] testData = [];
+ 	private int[] searchData = [];
+ 
+ 	/// <summary>
+ 	/// Gets or sets the number of elements to use in benchmarks.
+ 	/// </summary>
+ 	[Params(100, 1000, 10000)]
+ 	public int ElementCount { get; set; }
+ 
+ 	/// <summary>
+ 	/// Setup method called before each benchmark iteration.
+ 	/// </summary>
+ 	[GlobalSetup]
+ 	public void Setup()
+ 	{
+ 		// Generate test data with some duplicates
+ 		testData = new int[ElementCount];
+ 		for (int i = 0; i < ElementCount; i++)
+ 		{
+ 			testData[i] = random.Next(0, ElementCount / 2); // Creates duplicates
+ 		}
+ 
+ 		// Generate search data (mix of existing and non-existing values)
+ 		searchData = new int[100];
+ 		for (int i = 0; i < 50; i++)
+ 		{
+ 			searchData[i] = testData[random.Next(testData.Length)]; // Existing values
+ 		}
+ 		for (int i = 50; i < 100; i++)
+ 		{
+ 			searchData[i] = random.Next(ElementCount, ElementCount * 2); // Non-existing values
+ 		}
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark adding elements to InsertionOrderSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public InsertionOrderSet<int> InsertionOrderSet_Add()
+ 	{
+ 		InsertionOrderSet<int> set = new();
+ 		foreach (int item in testData)
+ 		{
+ 			set.Add(item);
+ 		}
+ 		return set;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark adding elements to HashSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public HashSet<int> HashSet_Add()
+ 	{
+ 		HashSet<int> set = [];
+ 		foreach (int item in testData)
+ 		{
+ 			set.Add(item);
+ 		}
+ 		return set;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark adding elements to SortedSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public SortedSet<int> SortedSet_Add()
+ 	{
+ 		SortedSet<int> set = [];
+ 		foreach (int item in testData)
+ 		{
+ 			set.Add(item);
+ 		}
+ 		return set;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark searching in InsertionOrderSet using Contains.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int InsertionOrderSet_Contains()
+ 	{
+ 		InsertionOrderSet<int> set = new(testData);
+ 		int found = 0;
+ 		foreach (int item in searchData)
+ 		{
+ 			if (set.Contains(item))
+ 			{
+ 				found++;
+ 			}
+ 		}
+ 		return found;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark searching in HashSet using Contains.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int HashSet_Contains()
+ 	{
+ 		HashSet<int> set = [.. testData];
+ 		int found = 0;
+ 		foreach (int item in searchData)
+ 		{
+ 			if (set.Contains(item))
+ 			{
+ 				found++;
+ 			}
+ 		}
+ 		return found;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark searching in SortedSet using Contains.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int SortedSet_Contains()
+ 	{
+ 		SortedSet<int> set = [.. testData];
+ 		int found = 0;
+ 		foreach (int item in searchData)
+ 		{
+ 			if (set.Contains(item))
+ 			{
+ 				found++;
+ 			}
+ 		}
+ 		return found;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark enumeration of InsertionOrderSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int InsertionOrderSet_Enumerate()
+ 	{
+ 		InsertionOrderSet<int> set = new(testData);
+ 		int sum = 0;
+ 		foreach (int item in set)
+ 		{
+ 			sum += item;
+ 		}
+ 		return sum;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark enumeration of HashSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int HashSet_Enumerate()
+ 	{
+ 		HashSet<int> set = [.. testData];
+ 		int sum = 0;
+ 		foreach (int item in set)
+ 		{
+ 			sum += item;
+ 		}
+ 		return sum;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark enumeration of SortedSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int SortedSet_Enumerate()
+ 	{
+ 		SortedSet<int> set = [.. testData];
+ 		int sum = 0;
+ 		foreach (int item in set)
+ 		{
+ 			sum += item;
+ 		}
+ 		return sum;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark removing elements from InsertionOrderSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public InsertionOrderSet<int> InsertionOrderSet_Remove()
+ 	{
+ 		InsertionOrderSet<int> set = new(testData);
+ 
+ 		// Remove every 10th unique element
+ 		int[] uniqueItems = set.ToArray();
+ 		for (int i = 0; i < uniqueItems.Length; i += 10)
+ 		{
+ 			set.Remove(uniqueItems[i]);
+ 		}
+ 
+ 		return set;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark removing elements from HashSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public HashSet<int> HashSet_Remove()
+ 	{
+ 		HashSet<int> set = [.. testData];
+ 
+ 		// Remove every 10th unique element
+ 		int[] uniqueItems = set.ToArray();
+ 		for (int i = 0; i < uniqueItems.Length; i += 10)
+ 		{
+ 			set.Remove(uniqueItems[i]);
+ 		}
+ 
+ 		return set;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark mixed operations (add, remove, search) on InsertionOrderSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public InsertionOrderSet<int> InsertionOrderSet_MixedOperations()
+ 	{
+ 		InsertionOrderSet<int> set = new();
+ 
+ 		// Add elements
+ 		foreach (int item in testData[..^100])
+ 		{
+ 			set.Add(item);
+ 		}
+ 
+ 		// Remove some elements
+ 		int[] toRemove = set.Take(10).ToArray();
+ 		foreach (int item in toRemove)
+ 		{
+ 			set.Remove(item);
+ 		}
+ 
+ 		// Add more elements
+ 		foreach (int item in testData[^100..])
+ 		{
+ 			set.Add(item);
+ 		}
+ 
+ 		return set;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark mixed operations (add, remove, search) on HashSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public HashSet<int> HashSet_MixedOperations()
+ 	{
+ 		HashSet<int> set = [];
+ 
+ 		// Add elements
+ 		foreach (int item in testData[..^100])
+ 		{
+ 			set.Add(item);
+ 		}
+ 
+ 		// Remove some elements
+ 		int[] toRemove = set.Take(10).ToArray();
+ 		foreach (int item in toRemove)
+ 		{
+ 			set.Remove(item);
+ 		}
+ 
+ 		// Add more elements
+ 		foreach (int item in testData[^100..])
+ 		{
+ 			set.Add(item);
+ 		}
+ 
+ 		return set;
+ 	}
+ } 
```

---

Now let me create the remaining benchmark files. I'll continue with the other benchmarks:

---

```diff
- 
+ // Copyright (c) ktsu.dev
+ // All rights reserved.
+ // Licensed under the MIT license.
+ 
+ using BenchmarkDotNet.Attributes;
+ using ktsu.Containers;
+ 
+ namespace ktsu.Containers.Benchmarks;
+ 
+ /// <summary>
+ /// Benchmarks for InsertionOrderMap performance compared to built-in collections.
+ /// </summary>
+ [MemoryDiagnoser]
+ [SimpleJob]
+ public class InsertionOrderMapBenchmarks
+ {
+ 	private readonly Random random = new(42); // Fixed seed for reproducible results
+ 	private KeyValuePair<int, string>[] testData = [];
+ 	private int[] searchKeys = [];
+ 
+ 	/// <summary>
+ 	/// Gets or sets the number of elements to use in benchmarks.
+ 	/// </summary>
+ 	[Params(100, 1000, 10000)]
+ 	public int ElementCount { get; set; }
+ 
+ 	/// <summary>
+ 	/// Setup method called before each benchmark iteration.
+ 	/// </summary>
+ 	[GlobalSetup]
+ 	public void Setup()
+ 	{
+ 		// Generate test data
+ 		testData = new KeyValuePair<int, string>[ElementCount];
+ 		for (int i = 0; i < ElementCount; i++)
+ 		{
+ 			int key = random.Next(0, ElementCount / 2); // Creates some duplicate keys
+ 			string value = $"Value_{key}_{i}";
+ 			testData[i] = new KeyValuePair<int, string>(key, value);
+ 		}
+ 
+ 		// Generate search keys (mix of existing and non-existing keys)
+ 		searchKeys = new int[100];
+ 		for (int i = 0; i < 50; i++)
+ 		{
+ 			searchKeys[i] = testData[random.Next(testData.Length)].Key; // Existing keys
+ 		}
+ 		for (int i = 50; i < 100; i++)
+ 		{
+ 			searchKeys[i] = random.Next(ElementCount, ElementCount * 2); // Non-existing keys
+ 		}
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark adding elements to InsertionOrderMap.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public InsertionOrderMap<int, string> InsertionOrderMap_Add()
+ 	{
+ 		InsertionOrderMap<int, string> map = new();
+ 		foreach (KeyValuePair<int, string> item in testData)
+ 		{
+ 			map.TryAdd(item.Key, item.Value);
+ 		}
+ 		return map;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark adding elements to Dictionary.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public Dictionary<int, string> Dictionary_Add()
+ 	{
+ 		Dictionary<int, string> dict = [];
+ 		foreach (KeyValuePair<int, string> item in testData)
+ 		{
+ 			dict.TryAdd(item.Key, item.Value);
+ 		}
+ 		return dict;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark adding elements to SortedDictionary.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public SortedDictionary<int, string> SortedDictionary_Add()
+ 	{
+ 		SortedDictionary<int, string> sortedDict = [];
+ 		foreach (KeyValuePair<int, string> item in testData)
+ 		{
+ 			sortedDict.TryAdd(item.Key, item.Value);
+ 		}
+ 		return sortedDict;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark searching in InsertionOrderMap using ContainsKey.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int InsertionOrderMap_ContainsKey()
+ 	{
+ 		InsertionOrderMap<int, string> map = new();
+ 		foreach (KeyValuePair<int, string> item in testData)
+ 		{
+ 			map.TryAdd(item.Key, item.Value);
+ 		}
+ 
+ 		int found = 0;
+ 		foreach (int key in searchKeys)
+ 		{
+ 			if (map.ContainsKey(key))
+ 			{
+ 				found++;
+ 			}
+ 		}
+ 		return found;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark searching in Dictionary using ContainsKey.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int Dictionary_ContainsKey()
+ 	{
+ 		Dictionary<int, string> dict = [];
+ 		foreach (KeyValuePair<int, string> item in testData)
+ 		{
+ 			dict.TryAdd(item.Key, item.Value);
+ 		}
+ 
+ 		int found = 0;
+ 		foreach (int key in searchKeys)
+ 		{
+ 			if (dict.ContainsKey(key))
+ 			{
+ 				found++;
+ 			}
+ 		}
+ 		return found;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark searching in SortedDictionary using ContainsKey.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int SortedDictionary_ContainsKey()
+ 	{
+ 		SortedDictionary<int, string> sortedDict = [];
+ 		foreach (KeyValuePair<int, string> item in testData)
+ 		{
+ 			sortedDict.TryAdd(item.Key, item.Value);
+ 		}
+ 
+ 		int found = 0;
+ 		foreach (int key in searchKeys)
+ 		{
+ 			if (sortedDict.ContainsKey(key))
+ 			{
+ 				found++;
+ 			}
+ 		}
+ 		return found;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark enumeration of InsertionOrderMap.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int InsertionOrderMap_Enumerate()
+ 	{
+ 		InsertionOrderMap<int, string> map = new();
+ 		foreach (KeyValuePair<int, string> item in testData)
+ 		{
+ 			map.TryAdd(item.Key, item.Value);
+ 		}
+ 
+ 		int sum = 0;
+ 		foreach (KeyValuePair<int, string> kvp in map)
+ 		{
+ 			sum += kvp.Key;
+ 		}
+ 		return sum;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark enumeration of Dictionary.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int Dictionary_Enumerate()
+ 	{
+ 		Dictionary<int, string> dict = [];
+ 		foreach (KeyValuePair<int, string> item in testData)
+ 		{
+ 			dict.TryAdd(item.Key, item.Value);
+ 		}
+ 
+ 		int sum = 0;
+ 		foreach (KeyValuePair<int, string> kvp in dict)
+ 		{
+ 			sum += kvp.Key;
+ 		}
+ 		return sum;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark removing elements from InsertionOrderMap.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public InsertionOrderMap<int, string> InsertionOrderMap_Remove()
+ 	{
+ 		InsertionOrderMap<int, string> map = new();
+ 		foreach (KeyValuePair<int, string> item in testData)
+ 		{
+ 			map.TryAdd(item.Key, item.Value);
+ 		}
+ 
+ 		// Remove every 10th unique key
+ 		int[] keysToRemove = map.Keys.Where((_, index) => index % 10 == 0).ToArray();
+ 		foreach (int key in keysToRemove)
+ 		{
+ 			map.Remove(key);
+ 		}
+ 
+ 		return map;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark removing elements from Dictionary.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public Dictionary<int, string> Dictionary_Remove()
+ 	{
+ 		Dictionary<int, string> dict = [];
+ 		foreach (KeyValuePair<int, string> item in testData)
+ 		{
+ 			dict.TryAdd(item.Key, item.Value);
+ 		}
+ 
+ 		// Remove every 10th unique key
+ 		int[] keysToRemove = dict.Keys.Where((_, index) => index % 10 == 0).ToArray();
+ 		foreach (int key in keysToRemove)
+ 		{
+ 			dict.Remove(key);
+ 		}
+ 
+ 		return dict;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark mixed operations (add, remove, search) on InsertionOrderMap.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public InsertionOrderMap<int, string> InsertionOrderMap_MixedOperations()
+ 	{
+ 		InsertionOrderMap<int, string> map = new();
+ 
+ 		// Add elements
+ 		foreach (KeyValuePair<int, string> item in testData[..^100])
+ 		{
+ 			map.TryAdd(item.Key, item.Value);
+ 		}
+ 
+ 		// Remove some elements
+ 		int[] keysToRemove = map.Keys.Take(10).ToArray();
+ 		foreach (int key in keysToRemove)
+ 		{
+ 			map.Remove(key);
+ 		}
+ 
+ 		// Add more elements
+ 		foreach (KeyValuePair<int, string> item in testData[^100..])
+ 		{
+ 			map.TryAdd(item.Key, item.Value);
+ 		}
+ 
+ 		return map;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark mixed operations (add, remove, search) on Dictionary.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public Dictionary<int, string> Dictionary_MixedOperations()
+ 	{
+ 		Dictionary<int, string> dict = [];
+ 
+ 		// Add elements
+ 		foreach (KeyValuePair<int, string> item in testData[..^100])
+ 		{
+ 			dict.TryAdd(item.Key, item.Value);
+ 		}
+ 
+ 		// Remove some elements
+ 		int[] keysToRemove = dict.Keys.Take(10).ToArray();
+ 		foreach (int key in keysToRemove)
+ 		{
+ 			dict.Remove(key);
+ 		}
+ 
+ 		// Add more elements
+ 		foreach (KeyValuePair<int, string> item in testData[^100..])
+ 		{
+ 			dict.TryAdd(item.Key, item.Value);
+ 		}
+ 
+ 		return dict;
+ 	}
+ } 
```

---



---

Now let me create the contiguous collection benchmarks:

---

```diff
- 
+ // Copyright (c) ktsu.dev
+ // All rights reserved.
+ // Licensed under the MIT license.
+ 
+ using BenchmarkDotNet.Attributes;
+ using ktsu.Containers;
+ 
+ namespace ktsu.Containers.Benchmarks;
+ 
+ /// <summary>
+ /// Benchmarks for ContiguousCollection performance compared to built-in collections.
+ /// Focus on cache efficiency and contiguous memory access patterns.
+ /// </summary>
+ [MemoryDiagnoser]
+ [SimpleJob]
+ public class ContiguousCollectionBenchmarks
+ {
+ 	private readonly Random random = new(42); // Fixed seed for reproducible results
+ 	private int[] testData = [];
+ 	private int[] searchData = [];
+ 
+ 	/// <summary>
+ 	/// Gets or sets the number of elements to use in benchmarks.
+ 	/// </summary>
+ 	[Params(100, 1000, 10000)]
+ 	public int ElementCount { get; set; }
+ 
+ 	/// <summary>
+ 	/// Setup method called before each benchmark iteration.
+ 	/// </summary>
+ 	[GlobalSetup]
+ 	public void Setup()
+ 	{
+ 		// Generate test data
+ 		testData = new int[ElementCount];
+ 		for (int i = 0; i < ElementCount; i++)
+ 		{
+ 			testData[i] = random.Next(0, ElementCount * 2);
+ 		}
+ 
+ 		// Generate search data (mix of existing and non-existing values)
+ 		searchData = new int[100];
+ 		for (int i = 0; i < 50; i++)
+ 		{
+ 			searchData[i] = testData[random.Next(testData.Length)]; // Existing values
+ 		}
+ 		for (int i = 50; i < 100; i++)
+ 		{
+ 			searchData[i] = random.Next(ElementCount * 2, ElementCount * 3); // Non-existing values
+ 		}
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark adding elements to ContiguousCollection.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public ContiguousCollection<int> ContiguousCollection_Add()
+ 	{
+ 		ContiguousCollection<int> collection = new();
+ 		foreach (int item in testData)
+ 		{
+ 			collection.Add(item);
+ 		}
+ 		return collection;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark adding elements to List (baseline comparison).
+ 	/// </summary>
+ 	[Benchmark]
+ 	public List<int> List_Add()
+ 	{
+ 		List<int> list = [];
+ 		foreach (int item in testData)
+ 		{
+ 			list.Add(item);
+ 		}
+ 		return list;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark adding elements to Array (fixed size comparison).
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int[] Array_Fill()
+ 	{
+ 		int[] array = new int[testData.Length];
+ 		for (int i = 0; i < testData.Length; i++)
+ 		{
+ 			array[i] = testData[i];
+ 		}
+ 		return array;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark searching in ContiguousCollection using Contains (cache-friendly).
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int ContiguousCollection_Contains()
+ 	{
+ 		ContiguousCollection<int> collection = new(testData);
+ 		int found = 0;
+ 		foreach (int item in searchData)
+ 		{
+ 			if (collection.Contains(item))
+ 			{
+ 				found++;
+ 			}
+ 		}
+ 		return found;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark searching in List using Contains.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int List_Contains()
+ 	{
+ 		List<int> list = [.. testData];
+ 		int found = 0;
+ 		foreach (int item in searchData)
+ 		{
+ 			if (list.Contains(item))
+ 			{
+ 				found++;
+ 			}
+ 		}
+ 		return found;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark enumeration of ContiguousCollection (optimal cache access).
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int ContiguousCollection_Enumerate()
+ 	{
+ 		ContiguousCollection<int> collection = new(testData);
+ 		int sum = 0;
+ 		foreach (int item in collection)
+ 		{
+ 			sum += item;
+ 		}
+ 		return sum;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark enumeration of List.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int List_Enumerate()
+ 	{
+ 		List<int> list = [.. testData];
+ 		int sum = 0;
+ 		foreach (int item in list)
+ 		{
+ 			sum += item;
+ 		}
+ 		return sum;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark indexed access in ContiguousCollection (cache-friendly random access).
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int ContiguousCollection_IndexedAccess()
+ 	{
+ 		ContiguousCollection<int> collection = new(testData);
+ 		int sum = 0;
+ 		for (int i = 0; i < collection.Count; i++)
+ 		{
+ 			sum += collection[i];
+ 		}
+ 		return sum;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark indexed access in List.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int List_IndexedAccess()
+ 	{
+ 		List<int> list = [.. testData];
+ 		int sum = 0;
+ 		for (int i = 0; i < list.Count; i++)
+ 		{
+ 			sum += list[i];
+ 		}
+ 		return sum;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark span access in ContiguousCollection (zero-copy operations).
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int ContiguousCollection_SpanAccess()
+ 	{
+ 		ContiguousCollection<int> collection = new(testData);
+ 		ReadOnlySpan<int> span = collection.AsReadOnlySpan();
+ 		int sum = 0;
+ 		for (int i = 0; i < span.Length; i++)
+ 		{
+ 			sum += span[i];
+ 		}
+ 		return sum;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark removing elements from ContiguousCollection.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public ContiguousCollection<int> ContiguousCollection_Remove()
+ 	{
+ 		ContiguousCollection<int> collection = new(testData);
+ 
+ 		// Remove every 10th element
+ 		for (int i = 0; i < testData.Length; i += 10)
+ 		{
+ 			collection.Remove(testData[i]);
+ 		}
+ 
+ 		return collection;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark removing elements from List.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public List<int> List_Remove()
+ 	{
+ 		List<int> list = [.. testData];
+ 
+ 		// Remove every 10th element
+ 		for (int i = 0; i < testData.Length; i += 10)
+ 		{
+ 			list.Remove(testData[i]);
+ 		}
+ 
+ 		return list;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark memory-intensive operations showing contiguous memory benefits.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public long ContiguousCollection_MemoryIntensiveOp()
+ 	{
+ 		ContiguousCollection<int> collection = new(testData);
+ 		long result = 0;
+ 
+ 		// Simulate cache-friendly sequential access pattern
+ 		for (int pass = 0; pass < 3; pass++)
+ 		{
+ 			for (int i = 0; i < collection.Count; i++)
+ 			{
+ 				result += collection[i] * (pass + 1);
+ 			}
+ 		}
+ 
+ 		return result;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark memory-intensive operations on List.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public long List_MemoryIntensiveOp()
+ 	{
+ 		List<int> list = [.. testData];
+ 		long result = 0;
+ 
+ 		// Simulate cache-friendly sequential access pattern
+ 		for (int pass = 0; pass < 3; pass++)
+ 		{
+ 			for (int i = 0; i < list.Count; i++)
+ 			{
+ 				result += list[i] * (pass + 1);
+ 			}
+ 		}
+ 
+ 		return result;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark mixed operations (add, remove, access) on ContiguousCollection.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public ContiguousCollection<int> ContiguousCollection_MixedOperations()
+ 	{
+ 		ContiguousCollection<int> collection = new();
+ 
+ 		// Add elements
+ 		foreach (int item in testData[..^100])
+ 		{
+ 			collection.Add(item);
+ 		}
+ 
+ 		// Access elements (cache-friendly)
+ 		int sum = 0;
+ 		for (int i = 0; i < collection.Count; i++)
+ 		{
+ 			sum += collection[i];
+ 		}
+ 
+ 		// Remove some elements
+ 		for (int i = 0; i < 50; i++)
+ 		{
+ 			collection.Remove(testData[i]);
+ 		}
+ 
+ 		// Add more elements
+ 		foreach (int item in testData[^100..])
+ 		{
+ 			collection.Add(item);
+ 		}
+ 
+ 		return collection;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark mixed operations (add, remove, access) on List.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public List<int> List_MixedOperations()
+ 	{
+ 		List<int> list = [];
+ 
+ 		// Add elements
+ 		foreach (int item in testData[..^100])
+ 		{
+ 			list.Add(item);
+ 		}
+ 
+ 		// Access elements
+ 		int sum = 0;
+ 		for (int i = 0; i < list.Count; i++)
+ 		{
+ 			sum += list[i];
+ 		}
+ 
+ 		// Remove some elements
+ 		for (int i = 0; i < 50; i++)
+ 		{
+ 			list.Remove(testData[i]);
+ 		}
+ 
+ 		// Add more elements
+ 		foreach (int item in testData[^100..])
+ 		{
+ 			list.Add(item);
+ 		}
+ 
+ 		return list;
+ 	}
+ } 
```

---

Now let me create the remaining two benchmark files in parallel:

---

```diff
- 
+ // Copyright (c) ktsu.dev
+ // All rights reserved.
+ // Licensed under the MIT license.
+ 
+ using BenchmarkDotNet.Attributes;
+ using ktsu.Containers;
+ 
+ namespace ktsu.Containers.Benchmarks;
+ 
+ /// <summary>
+ /// Benchmarks for ContiguousSet performance compared to built-in collections.
+ /// Focus on unique elements with contiguous memory layout for optimal cache performance.
+ /// </summary>
+ [MemoryDiagnoser]
+ [SimpleJob]
+ public class ContiguousSetBenchmarks
+ {
+ 	private readonly Random random = new(42); // Fixed seed for reproducible results
+ 	private int[] testData = [];
+ 	private int[] searchData = [];
+ 
+ 	/// <summary>
+ 	/// Gets or sets the number of elements to use in benchmarks.
+ 	/// </summary>
+ 	[Params(100, 1000, 10000)]
+ 	public int ElementCount { get; set; }
+ 
+ 	/// <summary>
+ 	/// Setup method called before each benchmark iteration.
+ 	/// </summary>
+ 	[GlobalSetup]
+ 	public void Setup()
+ 	{
+ 		// Generate test data with some duplicates
+ 		testData = new int[ElementCount];
+ 		for (int i = 0; i < ElementCount; i++)
+ 		{
+ 			testData[i] = random.Next(0, ElementCount / 2); // Creates duplicates
+ 		}
+ 
+ 		// Generate search data (mix of existing and non-existing values)
+ 		searchData = new int[100];
+ 		for (int i = 0; i < 50; i++)
+ 		{
+ 			searchData[i] = testData[random.Next(testData.Length)]; // Existing values
+ 		}
+ 		for (int i = 50; i < 100; i++)
+ 		{
+ 			searchData[i] = random.Next(ElementCount, ElementCount * 2); // Non-existing values
+ 		}
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark adding elements to ContiguousSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public ContiguousSet<int> ContiguousSet_Add()
+ 	{
+ 		ContiguousSet<int> set = new();
+ 		foreach (int item in testData)
+ 		{
+ 			set.Add(item);
+ 		}
+ 		return set;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark adding elements to HashSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public HashSet<int> HashSet_Add()
+ 	{
+ 		HashSet<int> set = [];
+ 		foreach (int item in testData)
+ 		{
+ 			set.Add(item);
+ 		}
+ 		return set;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark adding elements to SortedSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public SortedSet<int> SortedSet_Add()
+ 	{
+ 		SortedSet<int> set = [];
+ 		foreach (int item in testData)
+ 		{
+ 			set.Add(item);
+ 		}
+ 		return set;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark searching in ContiguousSet using Contains (cache-friendly linear search).
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int ContiguousSet_Contains()
+ 	{
+ 		ContiguousSet<int> set = new(testData);
+ 		int found = 0;
+ 		foreach (int item in searchData)
+ 		{
+ 			if (set.Contains(item))
+ 			{
+ 				found++;
+ 			}
+ 		}
+ 		return found;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark searching in HashSet using Contains.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int HashSet_Contains()
+ 	{
+ 		HashSet<int> set = [.. testData];
+ 		int found = 0;
+ 		foreach (int item in searchData)
+ 		{
+ 			if (set.Contains(item))
+ 			{
+ 				found++;
+ 			}
+ 		}
+ 		return found;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark searching in SortedSet using Contains.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int SortedSet_Contains()
+ 	{
+ 		SortedSet<int> set = [.. testData];
+ 		int found = 0;
+ 		foreach (int item in searchData)
+ 		{
+ 			if (set.Contains(item))
+ 			{
+ 				found++;
+ 			}
+ 		}
+ 		return found;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark enumeration of ContiguousSet (optimal cache access).
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int ContiguousSet_Enumerate()
+ 	{
+ 		ContiguousSet<int> set = new(testData);
+ 		int sum = 0;
+ 		foreach (int item in set)
+ 		{
+ 			sum += item;
+ 		}
+ 		return sum;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark enumeration of HashSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int HashSet_Enumerate()
+ 	{
+ 		HashSet<int> set = [.. testData];
+ 		int sum = 0;
+ 		foreach (int item in set)
+ 		{
+ 			sum += item;
+ 		}
+ 		return sum;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark enumeration of SortedSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int SortedSet_Enumerate()
+ 	{
+ 		SortedSet<int> set = [.. testData];
+ 		int sum = 0;
+ 		foreach (int item in set)
+ 		{
+ 			sum += item;
+ 		}
+ 		return sum;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark span access in ContiguousSet (zero-copy operations).
+ 	/// </summary>
+ 	[Benchmark]
+ 	public int ContiguousSet_SpanAccess()
+ 	{
+ 		ContiguousSet<int> set = new(testData);
+ 		ReadOnlySpan<int> span = set.AsReadOnlySpan();
+ 		int sum = 0;
+ 		for (int i = 0; i < span.Length; i++)
+ 		{
+ 			sum += span[i];
+ 		}
+ 		return sum;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark removing elements from ContiguousSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public ContiguousSet<int> ContiguousSet_Remove()
+ 	{
+ 		ContiguousSet<int> set = new(testData);
+ 
+ 		// Remove every 10th unique element
+ 		int[] uniqueItems = set.ToArray();
+ 		for (int i = 0; i < uniqueItems.Length; i += 10)
+ 		{
+ 			set.Remove(uniqueItems[i]);
+ 		}
+ 
+ 		return set;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark removing elements from HashSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public HashSet<int> HashSet_Remove()
+ 	{
+ 		HashSet<int> set = [.. testData];
+ 
+ 		// Remove every 10th unique element
+ 		int[] uniqueItems = set.ToArray();
+ 		for (int i = 0; i < uniqueItems.Length; i += 10)
+ 		{
+ 			set.Remove(uniqueItems[i]);
+ 		}
+ 
+ 		return set;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark memory-intensive operations showing contiguous memory benefits.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public long ContiguousSet_MemoryIntensiveOp()
+ 	{
+ 		ContiguousSet<int> set = new(testData);
+ 		long result = 0;
+ 
+ 		// Simulate cache-friendly sequential access pattern
+ 		for (int pass = 0; pass < 3; pass++)
+ 		{
+ 			foreach (int item in set)
+ 			{
+ 				result += item * (pass + 1);
+ 			}
+ 		}
+ 
+ 		return result;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark memory-intensive operations on HashSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public long HashSet_MemoryIntensiveOp()
+ 	{
+ 		HashSet<int> set = [.. testData];
+ 		long result = 0;
+ 
+ 		// Simulate access pattern (less cache-friendly)
+ 		for (int pass = 0; pass < 3; pass++)
+ 		{
+ 			foreach (int item in set)
+ 			{
+ 				result += item * (pass + 1);
+ 			}
+ 		}
+ 
+ 		return result;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark set operations (union, intersection) on ContiguousSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public ContiguousSet<int> ContiguousSet_SetOperations()
+ 	{
+ 		ContiguousSet<int> set1 = new(testData[..ElementCount / 2]);
+ 		ContiguousSet<int> set2 = new(testData[ElementCount / 4..]);
+ 
+ 		// Simulate union operation
+ 		ContiguousSet<int> result = new(set1);
+ 		foreach (int item in set2)
+ 		{
+ 			result.Add(item);
+ 		}
+ 
+ 		return result;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark set operations (union, intersection) on HashSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public HashSet<int> HashSet_SetOperations()
+ 	{
+ 		HashSet<int> set1 = [.. testData[..ElementCount / 2]];
+ 		HashSet<int> set2 = [.. testData[ElementCount / 4..]];
+ 
+ 		// Use built-in union operation
+ 		set1.UnionWith(set2);
+ 		return set1;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark mixed operations (add, remove, search) on ContiguousSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public ContiguousSet<int> ContiguousSet_MixedOperations()
+ 	{
+ 		ContiguousSet<int> set = new();
+ 
+ 		// Add elements
+ 		foreach (int item in testData[..^100])
+ 		{
+ 			set.Add(item);
+ 		}
+ 
+ 		// Remove some elements
+ 		int[] toRemove = set.Take(10).ToArray();
+ 		foreach (int item in toRemove)
+ 		{
+ 			set.Remove(item);
+ 		}
+ 
+ 		// Add more elements
+ 		foreach (int item in testData[^100..])
+ 		{
+ 			set.Add(item);
+ 		}
+ 
+ 		return set;
+ 	}
+ 
+ 	/// <summary>
+ 	/// Benchmark mixed operations (add, remove, search) on HashSet.
+ 	/// </summary>
+ 	[Benchmark]
+ 	public HashSet<int> HashSet_MixedOperations()
+ 	{
+ 		HashSet<int> set = [];
+ 
+ 		// Add elements
+ 		foreach (int item in testData[..^100])
+ 		{
+ 			set.Add(item);
+ 		}
+ 
+ 		// Remove some elements
+ 		int[] toRemove = set.Take(10).ToArray();
+ 		foreach (int item in toRemove)
+ 		{
+ 			set.Remove(item);
+ 		}
+ 
+ 		// Add more elements
+ 		foreach (int item in testData[^100..])
+ 		{
+ 			set.Add(item);
+ 		}
+ 
+ 		return set;
+ 	}
+ } 
```

---



---



---

The file wasn't created. Let me create it again with a simpler approach:

---



---



---

Let me see if the file already exists:

---

Read file: Containers.Benchmarks/InsertionOrderCollectionBenchmarks.cs

---



---

The file is empty. Let me write the content properly:

---



---



---

Let me fix the linter errors:

---



---

Now let me fix the collection initialization errors:

---



---



---

Let me fix the remaining collection initialization issues:

---



---



---

Let me fix the last remaining collection initialization error:

---



---

Great! Now let me continue with creating the remaining benchmark files and all the test files. Let me do this systematically by creating the rest of the benchmarks first:

---



---



---

Let me check the content of the ContiguousMapBenchmarks file:

---

Read file: Containers.Benchmarks/ContiguousMapBenchmarks.cs

---



---

Perfect! It looks like the ContiguousMapBenchmarks file was created successfully. Now I need to create all the test files. Let me start by creating the test files:

---



---



---

Let me create all the remaining test files systematically:

---

```diff
- 
+ // Copyright (c) ktsu.dev
+ // All rights reserved.
+ // Licensed under the MIT license.
+ 
+ namespace ktsu.Containers.Tests;
+ 
+ using System.Collections;
+ 
+ [TestClass]
+ public class InsertionOrderSetTests
+ {
+ 	[TestMethod]
+ 	public void Constructor_WithoutParameters_CreatesEmptySet()
+ 	{
+ 		// Arrange & Act
+ 		InsertionOrderSet<int> set = [];
+ 
+ 		// Assert
+ 		Assert.AreEqual(0, set.Count);
+ 		Assert.IsFalse(set.IsReadOnly);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Constructor_WithCapacity_CreatesSetWithCapacity()
+ 	{
+ 		// Arrange & Act
+ 		InsertionOrderSet<int> set = new(10);
+ 
+ 		// Assert
+ 		Assert.AreEqual(0, set.Count);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Constructor_WithCollection_AddsUniqueElementsInInsertionOrder()
+ 	{
+ 		// Arrange
+ 		int[] items = [3, 1, 4, 1, 5, 3, 2, 6]; // Has duplicates
+ 
+ 		// Act
+ 		InsertionOrderSet<int> set = [.. items];
+ 
+ 		// Assert
+ 		Assert.AreEqual(6, set.Count); // Only unique elements
+ 		Assert.AreEqual(3, set.ElementAt(0)); // First unique
+ 		Assert.AreEqual(1, set.ElementAt(1)); // Second unique
+ 		Assert.AreEqual(4, set.ElementAt(2)); // Third unique
+ 		Assert.AreEqual(5, set.ElementAt(3)); // Fourth unique
+ 		Assert.AreEqual(2, set.ElementAt(4)); // Fifth unique
+ 		Assert.AreEqual(6, set.ElementAt(5)); // Sixth unique
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Add_NewElement_ReturnsTrue()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set = [];
+ 
+ 		// Act
+ 		bool result = set.Add(5);
+ 
+ 		// Assert
+ 		Assert.IsTrue(result);
+ 		Assert.AreEqual(1, set.Count);
+ 		Assert.IsTrue(set.Contains(5));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Add_DuplicateElement_ReturnsFalse()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set = [5];
+ 
+ 		// Act
+ 		bool result = set.Add(5);
+ 
+ 		// Assert
+ 		Assert.IsFalse(result);
+ 		Assert.AreEqual(1, set.Count);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Add_MultipleElements_MaintainsInsertionOrder()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set = [];
+ 
+ 		// Act
+ 		set.Add(3);
+ 		set.Add(1);
+ 		set.Add(4);
+ 		set.Add(1); // Duplicate, should not be added
+ 		set.Add(2);
+ 
+ 		// Assert
+ 		Assert.AreEqual(4, set.Count);
+ 		Assert.AreEqual(3, set.ElementAt(0)); // First inserted
+ 		Assert.AreEqual(1, set.ElementAt(1)); // Second inserted
+ 		Assert.AreEqual(4, set.ElementAt(2)); // Third inserted
+ 		Assert.AreEqual(2, set.ElementAt(3)); // Fourth inserted
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Clear_WithElements_RemovesAllElements()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set = [.. new int[] { 1, 2, 3, 4, 5 }];
+ 
+ 		// Act
+ 		set.Clear();
+ 
+ 		// Assert
+ 		Assert.AreEqual(0, set.Count);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Contains_ExistingElement_ReturnsTrue()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set = [.. new int[] { 1, 2, 3, 4, 5 }];
+ 
+ 		// Act & Assert
+ 		Assert.IsTrue(set.Contains(3));
+ 		Assert.IsTrue(set.Contains(1));
+ 		Assert.IsTrue(set.Contains(5));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Contains_NonExistingElement_ReturnsFalse()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set = [.. new int[] { 1, 2, 3, 4, 5 }];
+ 
+ 		// Act & Assert
+ 		Assert.IsFalse(set.Contains(6));
+ 		Assert.IsFalse(set.Contains(0));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Remove_ExistingElement_RemovesAndReturnsTrue()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set = [.. new int[] { 3, 1, 4, 2 }];
+ 
+ 		// Act
+ 		bool result = set.Remove(1);
+ 
+ 		// Assert
+ 		Assert.IsTrue(result);
+ 		Assert.AreEqual(3, set.Count);
+ 		Assert.AreEqual(3, set.ElementAt(0));
+ 		Assert.AreEqual(4, set.ElementAt(1)); // Maintains order of remaining elements
+ 		Assert.AreEqual(2, set.ElementAt(2));
+ 		Assert.IsFalse(set.Contains(1));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Remove_NonExistingElement_ReturnsFalse()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set = [.. new int[] { 1, 2, 3 }];
+ 
+ 		// Act
+ 		bool result = set.Remove(5);
+ 
+ 		// Assert
+ 		Assert.IsFalse(result);
+ 		Assert.AreEqual(3, set.Count);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void CopyTo_ValidArray_CopiesElements()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set = [.. new int[] { 3, 1, 4, 2 }];
+ 		int[] array = new int[6];
+ 
+ 		// Act
+ 		set.CopyTo(array, 1);
+ 
+ 		// Assert
+ 		Assert.AreEqual(0, array[0]); // Unchanged
+ 		Assert.AreEqual(3, array[1]); // First inserted
+ 		Assert.AreEqual(1, array[2]); // Second inserted
+ 		Assert.AreEqual(4, array[3]); // Third inserted
+ 		Assert.AreEqual(2, array[4]); // Fourth inserted
+ 		Assert.AreEqual(0, array[5]); // Unchanged
+ 	}
+ 
+ 	[TestMethod]
+ 	public void GetEnumerator_IteratesInInsertionOrder()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set = [.. new int[] { 3, 1, 4, 1, 2 }]; // Contains duplicate
+ 		List<int> enumerated = [];
+ 
+ 		// Act
+ 		foreach (int item in set)
+ 		{
+ 			enumerated.Add(item);
+ 		}
+ 
+ 		// Assert
+ 		CollectionAssert.AreEqual(new int[] { 3, 1, 4, 2 }, enumerated); // No duplicates, insertion order
+ 	}
+ 
+ 	[TestMethod]
+ 	public void SetEquals_SameElements_ReturnsTrue()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set1 = [.. new int[] { 1, 2, 3 }];
+ 		InsertionOrderSet<int> set2 = [.. new int[] { 3, 1, 2 }]; // Different order
+ 
+ 		// Act & Assert
+ 		Assert.IsTrue(set1.SetEquals(set2));
+ 		Assert.IsTrue(set2.SetEquals(set1));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void SetEquals_DifferentElements_ReturnsFalse()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set1 = [.. new int[] { 1, 2, 3 }];
+ 		InsertionOrderSet<int> set2 = [.. new int[] { 1, 2, 4 }];
+ 
+ 		// Act & Assert
+ 		Assert.IsFalse(set1.SetEquals(set2));
+ 		Assert.IsFalse(set2.SetEquals(set1));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void IsSubsetOf_TrueSubset_ReturnsTrue()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> subset = [.. new int[] { 1, 3 }];
+ 		InsertionOrderSet<int> superset = [.. new int[] { 1, 2, 3, 4 }];
+ 
+ 		// Act & Assert
+ 		Assert.IsTrue(subset.IsSubsetOf(superset));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void IsSubsetOf_NotSubset_ReturnsFalse()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set1 = [.. new int[] { 1, 5 }];
+ 		InsertionOrderSet<int> set2 = [.. new int[] { 1, 2, 3, 4 }];
+ 
+ 		// Act & Assert
+ 		Assert.IsFalse(set1.IsSubsetOf(set2));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void IsSupersetOf_TrueSuperset_ReturnsTrue()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> superset = [.. new int[] { 1, 2, 3, 4 }];
+ 		InsertionOrderSet<int> subset = [.. new int[] { 1, 3 }];
+ 
+ 		// Act & Assert
+ 		Assert.IsTrue(superset.IsSupersetOf(subset));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void UnionWith_AddsNewElements_MaintainsInsertionOrder()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set1 = [.. new int[] { 1, 3 }];
+ 		InsertionOrderSet<int> set2 = [.. new int[] { 2, 3, 4 }];
+ 
+ 		// Act
+ 		set1.UnionWith(set2);
+ 
+ 		// Assert
+ 		Assert.AreEqual(4, set1.Count);
+ 		Assert.AreEqual(1, set1.ElementAt(0)); // Original element
+ 		Assert.AreEqual(3, set1.ElementAt(1)); // Original element
+ 		Assert.AreEqual(2, set1.ElementAt(2)); // New element from set2
+ 		Assert.AreEqual(4, set1.ElementAt(3)); // New element from set2
+ 	}
+ 
+ 	[TestMethod]
+ 	public void IntersectWith_KeepsCommonElements_MaintainsInsertionOrder()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set1 = [.. new int[] { 1, 2, 3, 4 }];
+ 		InsertionOrderSet<int> set2 = [.. new int[] { 2, 4, 5, 6 }];
+ 
+ 		// Act
+ 		set1.IntersectWith(set2);
+ 
+ 		// Assert
+ 		Assert.AreEqual(2, set1.Count);
+ 		Assert.AreEqual(2, set1.ElementAt(0)); // Common element, maintains original order
+ 		Assert.AreEqual(4, set1.ElementAt(1)); // Common element, maintains original order
+ 	}
+ 
+ 	[TestMethod]
+ 	public void ExceptWith_RemovesCommonElements()
+ 	{
+ 		// Arrange
+ 		InsertionOrderSet<int> set1 = [.. new int[] { 1, 2, 3, 4 }];
+ 		InsertionOrderSet<int> set2 = [.. new int[] { 2, 4 }];
+ 
+ 		// Act
+ 		set1.ExceptWith(set2);
+ 
+ 		// Assert
+ 		Assert.AreEqual(2, set1.Count);
+ 		Assert.AreEqual(1, set1.ElementAt(0));
+ 		Assert.AreEqual(3, set1.ElementAt(1));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void WorksWithStrings_MaintainsInsertionOrder()
+ 	{
+ 		// Arrange & Act
+ 		InsertionOrderSet<string> set = [.. new string[] { "charlie", "alpha", "bravo", "alpha" }]; // Contains duplicate
+ 
+ 		// Assert
+ 		Assert.AreEqual(3, set.Count); // Only unique elements
+ 		Assert.AreEqual("charlie", set.ElementAt(0)); // First unique
+ 		Assert.AreEqual("alpha", set.ElementAt(1));   // Second unique
+ 		Assert.AreEqual("bravo", set.ElementAt(2));   // Third unique
+ 	}
+ } 
```

---



---

Let me check if the InsertionOrderCollectionTests file was created:

---

Read file: Containers.Test/InsertionOrderCollectionTests.cs

---



---

Great! Now let me continue creating the remaining test files:

---

```diff
- 
+ // Copyright (c) ktsu.dev
+ // All rights reserved.
+ // Licensed under the MIT license.
+ 
+ namespace ktsu.Containers.Tests;
+ 
+ using System.Collections;
+ 
+ [TestClass]
+ public class InsertionOrderMapTests
+ {
+ 	[TestMethod]
+ 	public void Constructor_WithoutParameters_CreatesEmptyMap()
+ 	{
+ 		// Arrange & Act
+ 		InsertionOrderMap<int, string> map = [];
+ 
+ 		// Assert
+ 		Assert.AreEqual(0, map.Count);
+ 		Assert.IsFalse(map.IsReadOnly);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Constructor_WithCapacity_CreatesMapWithCapacity()
+ 	{
+ 		// Arrange & Act
+ 		InsertionOrderMap<int, string> map = new(10);
+ 
+ 		// Assert
+ 		Assert.AreEqual(0, map.Count);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Constructor_WithKeyValuePairs_AddsInInsertionOrder()
+ 	{
+ 		// Arrange
+ 		KeyValuePair<int, string>[] items = 
+ 		[
+ 			new(3, "three"),
+ 			new(1, "one"),
+ 			new(4, "four"),
+ 			new(2, "two")
+ 		];
+ 
+ 		// Act
+ 		InsertionOrderMap<int, string> map = [.. items];
+ 
+ 		// Assert
+ 		Assert.AreEqual(4, map.Count);
+ 		Assert.AreEqual("three", map[3]);
+ 		Assert.AreEqual("one", map[1]);
+ 		Assert.AreEqual("four", map[4]);
+ 		Assert.AreEqual("two", map[2]);
+ 
+ 		// Verify insertion order
+ 		int[] expectedOrder = [3, 1, 4, 2];
+ 		CollectionAssert.AreEqual(expectedOrder, map.Keys.ToArray());
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Add_NewKeyValuePair_AddsSuccessfully()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 
+ 		// Act
+ 		map.Add(5, "five");
+ 
+ 		// Assert
+ 		Assert.AreEqual(1, map.Count);
+ 		Assert.AreEqual("five", map[5]);
+ 		Assert.IsTrue(map.ContainsKey(5));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Add_DuplicateKey_ThrowsArgumentException()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(5, "five");
+ 
+ 		// Act & Assert
+ 		Assert.ThrowsException<ArgumentException>(() => map.Add(5, "another five"));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void TryAdd_NewKey_ReturnsTrue()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 
+ 		// Act
+ 		bool result = map.TryAdd(5, "five");
+ 
+ 		// Assert
+ 		Assert.IsTrue(result);
+ 		Assert.AreEqual(1, map.Count);
+ 		Assert.AreEqual("five", map[5]);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void TryAdd_DuplicateKey_ReturnsFalse()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(5, "five");
+ 
+ 		// Act
+ 		bool result = map.TryAdd(5, "another five");
+ 
+ 		// Assert
+ 		Assert.IsFalse(result);
+ 		Assert.AreEqual(1, map.Count);
+ 		Assert.AreEqual("five", map[5]); // Original value remains
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Indexer_ExistingKey_ReturnsValue()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(1, "one");
+ 		map.Add(2, "two");
+ 
+ 		// Act & Assert
+ 		Assert.AreEqual("one", map[1]);
+ 		Assert.AreEqual("two", map[2]);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Indexer_NonExistingKey_ThrowsKeyNotFoundException()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(1, "one");
+ 
+ 		// Act & Assert
+ 		Assert.ThrowsException<KeyNotFoundException>(() => map[2]);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Indexer_Set_UpdatesValue()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(1, "one");
+ 
+ 		// Act
+ 		map[1] = "ONE";
+ 
+ 		// Assert
+ 		Assert.AreEqual("ONE", map[1]);
+ 		Assert.AreEqual(1, map.Count); // Count should not change
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Indexer_SetNewKey_AddsKeyValuePair()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(1, "one");
+ 
+ 		// Act
+ 		map[2] = "two";
+ 
+ 		// Assert
+ 		Assert.AreEqual("two", map[2]);
+ 		Assert.AreEqual(2, map.Count);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void ContainsKey_ExistingKey_ReturnsTrue()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(1, "one");
+ 		map.Add(2, "two");
+ 
+ 		// Act & Assert
+ 		Assert.IsTrue(map.ContainsKey(1));
+ 		Assert.IsTrue(map.ContainsKey(2));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void ContainsKey_NonExistingKey_ReturnsFalse()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(1, "one");
+ 
+ 		// Act & Assert
+ 		Assert.IsFalse(map.ContainsKey(2));
+ 		Assert.IsFalse(map.ContainsKey(0));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void TryGetValue_ExistingKey_ReturnsTrueWithValue()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(1, "one");
+ 
+ 		// Act
+ 		bool result = map.TryGetValue(1, out string? value);
+ 
+ 		// Assert
+ 		Assert.IsTrue(result);
+ 		Assert.AreEqual("one", value);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void TryGetValue_NonExistingKey_ReturnsFalseWithDefault()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(1, "one");
+ 
+ 		// Act
+ 		bool result = map.TryGetValue(2, out string? value);
+ 
+ 		// Assert
+ 		Assert.IsFalse(result);
+ 		Assert.IsNull(value);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Remove_ExistingKey_RemovesAndReturnsTrue()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(1, "one");
+ 		map.Add(2, "two");
+ 		map.Add(3, "three");
+ 
+ 		// Act
+ 		bool result = map.Remove(2);
+ 
+ 		// Assert
+ 		Assert.IsTrue(result);
+ 		Assert.AreEqual(2, map.Count);
+ 		Assert.IsFalse(map.ContainsKey(2));
+ 		Assert.IsTrue(map.ContainsKey(1));
+ 		Assert.IsTrue(map.ContainsKey(3));
+ 
+ 		// Verify order maintained
+ 		int[] expectedOrder = [1, 3];
+ 		CollectionAssert.AreEqual(expectedOrder, map.Keys.ToArray());
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Remove_NonExistingKey_ReturnsFalse()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(1, "one");
+ 
+ 		// Act
+ 		bool result = map.Remove(2);
+ 
+ 		// Assert
+ 		Assert.IsFalse(result);
+ 		Assert.AreEqual(1, map.Count);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Clear_WithElements_RemovesAllElements()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(1, "one");
+ 		map.Add(2, "two");
+ 		map.Add(3, "three");
+ 
+ 		// Act
+ 		map.Clear();
+ 
+ 		// Assert
+ 		Assert.AreEqual(0, map.Count);
+ 		Assert.IsFalse(map.ContainsKey(1));
+ 		Assert.IsFalse(map.ContainsKey(2));
+ 		Assert.IsFalse(map.ContainsKey(3));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Keys_ReturnsKeysInInsertionOrder()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(3, "three");
+ 		map.Add(1, "one");
+ 		map.Add(4, "four");
+ 		map.Add(2, "two");
+ 
+ 		// Act
+ 		int[] keys = map.Keys.ToArray();
+ 
+ 		// Assert
+ 		int[] expectedOrder = [3, 1, 4, 2];
+ 		CollectionAssert.AreEqual(expectedOrder, keys);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Values_ReturnsValuesInInsertionOrder()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(3, "three");
+ 		map.Add(1, "one");
+ 		map.Add(4, "four");
+ 		map.Add(2, "two");
+ 
+ 		// Act
+ 		string[] values = map.Values.ToArray();
+ 
+ 		// Assert
+ 		string[] expectedOrder = ["three", "one", "four", "two"];
+ 		CollectionAssert.AreEqual(expectedOrder, values);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void GetEnumerator_IteratesInInsertionOrder()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(3, "three");
+ 		map.Add(1, "one");
+ 		map.Add(4, "four");
+ 		map.Add(2, "two");
+ 
+ 		// Act
+ 		List<KeyValuePair<int, string>> enumerated = [];
+ 		foreach (KeyValuePair<int, string> kvp in map)
+ 		{
+ 			enumerated.Add(kvp);
+ 		}
+ 
+ 		// Assert
+ 		Assert.AreEqual(4, enumerated.Count);
+ 		Assert.AreEqual(3, enumerated[0].Key);
+ 		Assert.AreEqual("three", enumerated[0].Value);
+ 		Assert.AreEqual(1, enumerated[1].Key);
+ 		Assert.AreEqual("one", enumerated[1].Value);
+ 		Assert.AreEqual(4, enumerated[2].Key);
+ 		Assert.AreEqual("four", enumerated[2].Value);
+ 		Assert.AreEqual(2, enumerated[3].Key);
+ 		Assert.AreEqual("two", enumerated[3].Value);
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Contains_ExistingKeyValuePair_ReturnsTrue()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(1, "one");
+ 		map.Add(2, "two");
+ 
+ 		// Act & Assert
+ 		Assert.IsTrue(map.Contains(new KeyValuePair<int, string>(1, "one")));
+ 		Assert.IsTrue(map.Contains(new KeyValuePair<int, string>(2, "two")));
+ 	}
+ 
+ 	[TestMethod]
+ 	public void Contains_NonExistingKeyValuePair_ReturnsFalse()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(1, "one");
+ 
+ 		// Act & Assert
+ 		Assert.IsFalse(map.Contains(new KeyValuePair<int, string>(1, "ONE"))); // Wrong value
+ 		Assert.IsFalse(map.Contains(new KeyValuePair<int, string>(2, "two"))); // Wrong key
+ 	}
+ 
+ 	[TestMethod]
+ 	public void CopyTo_ValidArray_CopiesElements()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 		map.Add(3, "three");
+ 		map.Add(1, "one");
+ 
+ 		KeyValuePair<int, string>[] array = new KeyValuePair<int, string>[4];
+ 
+ 		// Act
+ 		map.CopyTo(array, 1);
+ 
+ 		// Assert
+ 		Assert.AreEqual(default, array[0]); // Unchanged
+ 		Assert.AreEqual(new KeyValuePair<int, string>(3, "three"), array[1]);
+ 		Assert.AreEqual(new KeyValuePair<int, string>(1, "one"), array[2]);
+ 		Assert.AreEqual(default, array[3]); // Unchanged
+ 	}
+ 
+ 	[TestMethod]
+ 	public void MaintainsInsertionOrder_AfterMultipleOperations()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<int, string> map = [];
+ 
+ 		// Act
+ 		map.Add(5, "five");
+ 		map.Add(1, "one");
+ 		map.Add(3, "three");
+ 		map.Remove(1);
+ 		map.Add(2, "two");
+ 		map.Add(4, "four");
+ 		map.Remove(3);
+ 
+ 		// Assert
+ 		int[] expectedOrder = [5, 2, 4]; // Insertion order minus removed items
+ 		CollectionAssert.AreEqual(expectedOrder, map.Keys.ToArray());
+ 	}
+ 
+ 	[TestMethod]
+ 	public void WorksWithCustomTypes()
+ 	{
+ 		// Arrange
+ 		InsertionOrderMap<string, int> map = [];
+ 
+ 		// Act
+ 		map.Add("charlie", 3);
+ 		map.Add("alpha", 1);
+ 		map.Add("bravo", 2);
+ 
+ 		// Assert
+ 		string[] expectedKeyOrder = ["charlie", "alpha", "bravo"];
+ 		CollectionAssert.AreEqual(expectedKeyOrder, map.Keys.ToArray());
+ 	}
+ } 
```

---



---

Now let me create the contiguous collection tests:

---



---



---

Let me check if the file exists and is empty:

---

Read file: Containers.Test/ContiguousCollectionTests.cs

---



---

Great! The ContiguousCollectionTests was already created. Now let me create the remaining test files:

---



---





---

